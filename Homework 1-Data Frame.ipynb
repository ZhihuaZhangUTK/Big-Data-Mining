{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles: 3666\n",
      "Number of topic-article pairs:  6252\n"
     ]
    }
   ],
   "source": [
    "dir =  r'Data'\n",
    "topic_list = ['money', 'fx', 'crude', 'grain','trade', 'interest', 'wheat', 'ship', 'corn', 'oil', 'dlr', 'gas', 'oilseed', 'supply', 'sugar', 'gnp', 'coffee','veg', 'gold', 'soybean', 'bop',\n",
    "'livestock', 'cpi']\n",
    "\n",
    "# saving list\n",
    "docs = []\n",
    "data = []\n",
    "# count articles\n",
    "cnt= 0 \n",
    "\n",
    "# find topic+article pairs\n",
    "for file in os.listdir(dir):\n",
    "    if file.split('.')[-1]=='sgm':\n",
    "        path = os.path.join(dir,file)\n",
    "        with open(path,'rb') as fp:\n",
    "            soup = BeautifulSoup(fp,\"lxml\")\n",
    "        for tr in soup.find_all('reuters'):\n",
    "            for topic in tr.topics.children:\n",
    "                if topic:\n",
    "                    if topic.string in topic_list:\n",
    "                        content =  tr.find('text').contents[-1]\n",
    "                        if (topic.string, content) not in docs:\n",
    "                            docs.append((topic.string, content))\n",
    "                        if content not in data:\n",
    "                            data.append(content)\n",
    "                            cnt+=1\n",
    "                    else:\n",
    "                        split = topic.string.split('-')\n",
    "                        for s in split:\n",
    "                            if s in topic_list:\n",
    "                                content = tr.find('text').contents[-1]\n",
    "                                if (s,content) not in docs:\n",
    "                                    docs.append((s, content))\n",
    "                                if content not in data:\n",
    "                                    data.append(content)\n",
    "                                    cnt+=1                 \n",
    "print(\"Number of articles:\", cnt)\n",
    "print(\"Number of topic-article pairs: \", len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokized topic-article pairs:  6235\n"
     ]
    }
   ],
   "source": [
    "# stop words\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# tokenize function\n",
    "def tokenize(text):\n",
    "    min_length = 3\n",
    "    words = map(lambda word: word.lower(), word_tokenize(text))\n",
    "    words = [word for word in words if word not in stop_words] \n",
    "    tokens = list(map(lambda token: PorterStemmer().stem(token), words));\n",
    "    p = re.compile('[a-zA-Z]+');\n",
    "    filtered_tokens = list(filter(lambda token: p.match(token) and len(token)>=min_length, tokens));\n",
    "    return filtered_tokens\n",
    "\n",
    "documents = []\n",
    "spark_data = []\n",
    "# get filtered docs\n",
    "for pairs in docs:\n",
    "    text = tokenize(pairs[1])\n",
    "    if text:\n",
    "        spark_data.append((pairs[0], text))\n",
    "        documents.append((pairs[0], \" \".join(text)))\n",
    "print(\"Number of tokized topic-article pairs: \", len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('grain', 'u.s. agricultur depart report farmer-own reserv nation five-day averag price februari follow dlrs/bu-sorghum cwt natl loan releas call avg rate-x level price price wheat corn rate natl loan releas call avg rate-x level price price oat barley n.a sorghum reserv iii matur level reflect grain enter oct feedgrain juli wheat level wheat/barley corn/sorghum level cover wheat enter januari x-1986 rate y-dlr per cwt n.a.-not avail reuter')\n",
      "('wheat', 'u.s. agricultur depart report farmer-own reserv nation five-day averag price februari follow dlrs/bu-sorghum cwt natl loan releas call avg rate-x level price price wheat corn rate natl loan releas call avg rate-x level price price oat barley n.a sorghum reserv iii matur level reflect grain enter oct feedgrain juli wheat level wheat/barley corn/sorghum level cover wheat enter januari x-1986 rate y-dlr per cwt n.a.-not avail reuter')\n",
      "('corn', 'u.s. agricultur depart report farmer-own reserv nation five-day averag price februari follow dlrs/bu-sorghum cwt natl loan releas call avg rate-x level price price wheat corn rate natl loan releas call avg rate-x level price price oat barley n.a sorghum reserv iii matur level reflect grain enter oct feedgrain juli wheat level wheat/barley corn/sorghum level cover wheat enter januari x-1986 rate y-dlr per cwt n.a.-not avail reuter')\n",
      "('veg', 'argentin grain board figur show crop registr grain oilse product februari thousand tonn show futur shipment month total total februari bracket bread wheat prev feb march total maiz mar total nil sorghum nil nil oilse export registr sunflowerse total soybean may total nil board also detail export registr subproduct follow subproduct wheat prev feb march apr total linse prev feb mar apr total soybean prev feb mar nil apr nil may total sunflowerse prev feb mar apr total veget oil registr sunoil prev feb mar apr may nil jun total linoil prev feb mar apr total soybean oil prev feb mar nil apr may jun jul total reuter')\n",
      "('oil', 'argentin grain board figur show crop registr grain oilse product februari thousand tonn show futur shipment month total total februari bracket bread wheat prev feb march total maiz mar total nil sorghum nil nil oilse export registr sunflowerse total soybean may total nil board also detail export registr subproduct follow subproduct wheat prev feb march apr total linse prev feb mar apr total soybean prev feb mar nil apr nil may total sunflowerse prev feb mar apr total veget oil registr sunoil prev feb mar apr may nil jun total linoil prev feb mar apr total soybean oil prev feb mar nil apr may jun jul total reuter')\n",
      "('soybean', 'argentin grain board figur show crop registr grain oilse product februari thousand tonn show futur shipment month total total februari bracket bread wheat prev feb march total maiz mar total nil sorghum nil nil oilse export registr sunflowerse total soybean may total nil board also detail export registr subproduct follow subproduct wheat prev feb march apr total linse prev feb mar apr total soybean prev feb mar nil apr nil may total sunflowerse prev feb mar apr total veget oil registr sunoil prev feb mar apr may nil jun total linoil prev feb mar apr total soybean oil prev feb mar nil apr may jun jul total reuter')\n",
      "('oilseed', 'argentin grain board figur show crop registr grain oilse product februari thousand tonn show futur shipment month total total februari bracket bread wheat prev feb march total maiz mar total nil sorghum nil nil oilse export registr sunflowerse total soybean may total nil board also detail export registr subproduct follow subproduct wheat prev feb march apr total linse prev feb mar apr total soybean prev feb mar nil apr nil may total sunflowerse prev feb mar apr total veget oil registr sunoil prev feb mar apr may nil jun total linoil prev feb mar apr total soybean oil prev feb mar nil apr may jun jul total reuter')\n",
      "('corn', 'argentin grain board figur show crop registr grain oilse product februari thousand tonn show futur shipment month total total februari bracket bread wheat prev feb march total maiz mar total nil sorghum nil nil oilse export registr sunflowerse total soybean may total nil board also detail export registr subproduct follow subproduct wheat prev feb march apr total linse prev feb mar apr total soybean prev feb mar nil apr nil may total sunflowerse prev feb mar apr total veget oil registr sunoil prev feb mar apr may nil jun total linoil prev feb mar apr total soybean oil prev feb mar nil apr may jun jul total reuter')\n",
      "('grain', 'argentin grain board figur show crop registr grain oilse product februari thousand tonn show futur shipment month total total februari bracket bread wheat prev feb march total maiz mar total nil sorghum nil nil oilse export registr sunflowerse total soybean may total nil board also detail export registr subproduct follow subproduct wheat prev feb march apr total linse prev feb mar apr total soybean prev feb mar nil apr nil may total sunflowerse prev feb mar apr total veget oil registr sunoil prev feb mar apr may nil jun total linoil prev feb mar apr total soybean oil prev feb mar nil apr may jun jul total reuter')\n",
      "('wheat', 'argentin grain board figur show crop registr grain oilse product februari thousand tonn show futur shipment month total total februari bracket bread wheat prev feb march total maiz mar total nil sorghum nil nil oilse export registr sunflowerse total soybean may total nil board also detail export registr subproduct follow subproduct wheat prev feb march apr total linse prev feb mar apr total soybean prev feb mar nil apr nil may total sunflowerse prev feb mar apr total veget oil registr sunoil prev feb mar apr may nil jun total linoil prev feb mar apr total soybean oil prev feb mar nil apr may jun jul total reuter')\n"
     ]
    }
   ],
   "source": [
    "# print ten topic-body pairs\n",
    "for i in range(10):\n",
    "    print(documents[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# traning data saving path\n",
    "training_data = r'training_test_data.txt'\n",
    "\n",
    "# write to file\n",
    "with open(training_data,'w') as f:\n",
    "    for document in documents:\n",
    "        topic = document[0]\n",
    "        article=document[1]\n",
    "        f.write(topic+ ', '+article+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average time for split data 50/40: 0.342742582197\n",
      "The average time for split data 60/30: 0.342757883485\n",
      "The average time for split data 70/20: 0.343303929431\n"
     ]
    }
   ],
   "source": [
    "# tf-idf without spark\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import time\n",
    "df = pd.DataFrame(documents, columns=['topic', 'tokens'])\n",
    "# training_test_data X and Y without Spark\n",
    "start = time.time()\n",
    "vect = TfidfVectorizer()\n",
    "X = vect.fit_transform(df['tokens'])\n",
    "#print(time.time()-start)   # calculate time \n",
    "\n",
    "# convert categories to labels\n",
    "from sklearn import preprocessing \n",
    "label = preprocessing.LabelEncoder()\n",
    "Y = label.fit_transform(df['topic'])\n",
    "\n",
    "\n",
    "# naive bayes tranining \n",
    "X_train,X_validate,Y_train,Y_validate  = train_test_split(X,Y, test_size = 0.1, random_state=1234)\n",
    "\n",
    "# funtion to get the average score with runing model ten times\n",
    "def ave_score(split):\n",
    "    score = 0\n",
    "    for i in range(10):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(X_train,Y_train, test_size = split)\n",
    "        nb = MultinomialNB()\n",
    "        nb.fit(x_train,y_train)\n",
    "        predict = nb.predict(x_test)\n",
    "        score += accuracy_score(predict, y_test)\n",
    "    return score/10   \n",
    "\n",
    "# split the data 50/40\n",
    "print(\"The average time for split data 50/40:\", ave_score(4/9))\n",
    "# split the data 60/30\n",
    "print(\"The average time for split data 60/30:\", ave_score(3/9))\n",
    "# split the data 70/20\n",
    "print(\"The average time for split data 70/20:\", ave_score(2/9))                  \n",
    "# the more the training data, the big the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tf-idf without spark: 0.5179998874664307\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import time\n",
    "df = pd.DataFrame(documents, columns=['topic', 'tokens'])\n",
    "# tf-idf without spark\n",
    "start = time.time()\n",
    "vect = TfidfVectorizer()\n",
    "X = vect.fit_transform(df['tokens'])\n",
    "print(\"The tf-idf without spark:\", time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert categories to labels\n",
    "df = pd.DataFrame(documents, columns=['topic', 'articles'])\n",
    "from sklearn import preprocessing \n",
    "label = preprocessing.LabelEncoder()\n",
    "df['topic'] = label.fit_transform(df['topic'])\n",
    "df.to_csv('data.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|topic|            articles|                body|\n",
      "+-----+--------------------+--------------------+\n",
      "|   10|u.s. agricultur d...|[u.s., agricultur...|\n",
      "|   22|u.s. agricultur d...|[u.s., agricultur...|\n",
      "|    2|u.s. agricultur d...|[u.s., agricultur...|\n",
      "|   21|argentin grain bo...|[argentin, grain,...|\n",
      "|   14|argentin grain bo...|[argentin, grain,...|\n",
      "|   17|argentin grain bo...|[argentin, grain,...|\n",
      "|   15|argentin grain bo...|[argentin, grain,...|\n",
      "|    2|argentin grain bo...|[argentin, grain,...|\n",
      "|   10|argentin grain bo...|[argentin, grain,...|\n",
      "|   22|argentin grain bo...|[argentin, grain,...|\n",
      "|   22|commod credit cor...|[commod, credit, ...|\n",
      "|   10|commod credit cor...|[commod, credit, ...|\n",
      "|   13|      blah blah blah|  [blah, blah, blah]|\n",
      "|   19|      blah blah blah|  [blah, blah, blah]|\n",
      "|    1|intern coffe orga...|[intern, coffe, o...|\n",
      "|   16|mclean industri i...|[mclean, industri...|\n",
      "|   18|sugar import subj...|[sugar, import, s...|\n",
      "|   20|inflat plan initi...|[inflat, plan, in...|\n",
      "|   16|panama canal comm...|[panama, canal, c...|\n",
      "|   10|commod credit cor...|[commod, credit, ...|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- topic: integer (nullable = true)\n",
      " |-- articles: string (nullable = true)\n",
      " |-- body: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# data frame\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, NGram, ChiSqSelector\n",
    "from pyspark.ml.classification import NaiveBayes, NaiveBayesModel\n",
    "import pyspark.sql.functions\n",
    "\n",
    "df = spark.read.csv(\"data.csv\",header=True,inferSchema=True)\n",
    "# tokenize words\n",
    "#tokenizer = Tokenizer(inputCol=\"articles\", outputCol=\"tokens\")\n",
    "#df = tokenizer.transform(df)\n",
    "split_col = pyspark.sql.functions.split(df['articles'], ' ')\n",
    "df = df.withColumn(\"body\", split_col)\n",
    "df.show()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tf-idf with spark: 1.124000072479248\n"
     ]
    }
   ],
   "source": [
    "#tfidf with spark\n",
    "import time\n",
    "start =time.time()\n",
    "hashingTF = HashingTF(inputCol=\"body\", outputCol=\"term_freq\")\n",
    "df = hashingTF.transform(df)\n",
    "idf = IDF(inputCol=\"term_freq\", outputCol=\"tfidf\", minDocFreq=5)\n",
    "idfModel = idf.fit(df)\n",
    "df = idfModel.transform(df)\n",
    "print(\"The tf-idf with spark:\", time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train samples: 5625\n",
      "test samples: 610\n"
     ]
    }
   ],
   "source": [
    "#test train split\n",
    "train,validate = df.select(\"tfidf\",\"topic\").randomSplit([0.9, 0.1],seed=1234)\n",
    "print(\"train samples:\", train.count())\n",
    "print(\"test samples:\",validate.count())\n",
    "\n",
    "output  = r'model/'\n",
    "#apply naive bayes function \n",
    "def Bayes(split):\n",
    "    ave = 0\n",
    "    for i in range(10):\n",
    "        train_data, test_data = train.select(\"tfidf\",\"topic\").randomSplit([split/90, 1-split/90]) \n",
    "        #apply naive bayes\n",
    "        nb = NaiveBayes(featuresCol=\"tfidf\", labelCol=\"topic\", predictionCol=\"NB_pred\",\n",
    "                        probabilityCol=\"NB_prob\", rawPredictionCol=\"NB_rawPred\")\n",
    "        nbModel = nb.fit(train_data)\n",
    "        test = nbModel.transform(test_data)\n",
    "        #test.show()\n",
    "        #get test accuracy\n",
    "        total = test.count()\n",
    "        correct = test.where(test['topic'] == test['NB_pred']).count()\n",
    "        print(\"naive bayes unigrams test accuracy:\", correct/total)\n",
    "        ave+=correct/total\n",
    "        # save model\n",
    "        nbModel.save(output +'model' + '_'+str(split)+ '_'+str(i))\n",
    "    print(\"The average model accuracy: \", ave/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive bayes unigrams test accuracy: 0.37220843672456577\n",
      "naive bayes unigrams test accuracy: 0.33965125094768767\n",
      "naive bayes unigrams test accuracy: 0.3776167471819646\n",
      "naive bayes unigrams test accuracy: 0.3557312252964427\n",
      "naive bayes unigrams test accuracy: 0.35753749013417524\n",
      "naive bayes unigrams test accuracy: 0.3692679002413516\n",
      "naive bayes unigrams test accuracy: 0.3745082612116444\n",
      "naive bayes unigrams test accuracy: 0.36726703210649964\n",
      "naive bayes unigrams test accuracy: 0.35004042037186744\n",
      "naive bayes unigrams test accuracy: 0.36313291139240506\n",
      "The average model accuracy:  0.36269616756086037\n"
     ]
    }
   ],
   "source": [
    "# split 70/20\n",
    "Bayes(70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive bayes unigrams test accuracy: 0.35400105988341285\n",
      "naive bayes unigrams test accuracy: 0.35771920387305\n",
      "naive bayes unigrams test accuracy: 0.35281501340482574\n",
      "naive bayes unigrams test accuracy: 0.37567567567567567\n",
      "naive bayes unigrams test accuracy: 0.3520381154049762\n",
      "naive bayes unigrams test accuracy: 0.3662486938349007\n",
      "naive bayes unigrams test accuracy: 0.3605333333333333\n",
      "naive bayes unigrams test accuracy: 0.36015325670498083\n",
      "naive bayes unigrams test accuracy: 0.38064859117490696\n",
      "naive bayes unigrams test accuracy: 0.3629160063391442\n",
      "The average model accuracy:  0.36227489496292065\n"
     ]
    }
   ],
   "source": [
    "# split 60/30\n",
    "Bayes(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive bayes unigrams test accuracy: 0.35282176207876575\n",
      "naive bayes unigrams test accuracy: 0.35119280406726633\n",
      "naive bayes unigrams test accuracy: 0.35140482785912147\n",
      "naive bayes unigrams test accuracy: 0.3578990228013029\n",
      "naive bayes unigrams test accuracy: 0.3679052674561045\n",
      "naive bayes unigrams test accuracy: 0.3637826961770624\n",
      "naive bayes unigrams test accuracy: 0.3627760252365931\n",
      "naive bayes unigrams test accuracy: 0.3582443653618031\n",
      "naive bayes unigrams test accuracy: 0.3702970297029703\n",
      "naive bayes unigrams test accuracy: 0.35053235053235055\n",
      "The average model accuracy:  0.358685615127334\n"
     ]
    }
   ],
   "source": [
    "# split 50/40\n",
    "Bayes(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model/model_50_0: 0.3557377049180328\n",
      "model/model_50_1: 0.3295081967213115\n",
      "model/model_50_2: 0.3377049180327869\n"
     ]
    }
   ],
   "source": [
    "# load model to estimate the validate data\n",
    "model_list = os.listdir(output)\n",
    "for file in model_list[:3]:\n",
    "    path = os.path.join(output, file)\n",
    "    #print(path)\n",
    "    model = NaiveBayesModel.load(path)\n",
    "    val = model.transform(validate)\n",
    "    #get test accuracy\n",
    "    total = val.count()\n",
    "    correct = val.where(val['topic'] == val['NB_pred']).count()\n",
    "    print(path + ':', correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model/model_50_3: 0.34918032786885245\n",
      "model/model_50_4: 0.3475409836065574\n",
      "model/model_50_5: 0.3360655737704918\n"
     ]
    }
   ],
   "source": [
    "for file in model_list[3:6]:\n",
    "    path = os.path.join(output, file)\n",
    "    #print(path)\n",
    "    model = NaiveBayesModel.load(path)\n",
    "    val = model.transform(validate)\n",
    "    #get test accuracy\n",
    "    total = val.count()\n",
    "    correct = val.where(val['topic'] == val['NB_pred']).count()\n",
    "    print(path + ':', correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model/model_50_6: 0.3377049180327869\n",
      "model/model_50_7: 0.34590163934426227\n",
      "model/model_50_8: 0.3377049180327869\n"
     ]
    }
   ],
   "source": [
    "for file in model_list[6:9]:\n",
    "    path = os.path.join(output, file)\n",
    "    #print(path)\n",
    "    model = NaiveBayesModel.load(path)\n",
    "    val = model.transform(validate)\n",
    "    #get test accuracy\n",
    "    total = val.count()\n",
    "    correct = val.where(val['topic'] == val['NB_pred']).count()\n",
    "    print(path + ':', correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model/model_50_9: 0.35081967213114756\n",
      "model/model_60_0: 0.3475409836065574\n",
      "model/model_60_1: 0.3344262295081967\n"
     ]
    }
   ],
   "source": [
    "for file in model_list[9:12]:\n",
    "    path = os.path.join(output, file)\n",
    "    #print(path)\n",
    "    model = NaiveBayesModel.load(path)\n",
    "    val = model.transform(validate)\n",
    "    #get test accuracy\n",
    "    total = val.count()\n",
    "    correct = val.where(val['topic'] == val['NB_pred']).count()\n",
    "    print(path + ':', correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model/model_60_2: 0.3295081967213115\n",
      "model/model_60_3: 0.3524590163934426\n",
      "model/model_60_4: 0.33114754098360655\n"
     ]
    }
   ],
   "source": [
    "for file in model_list[12:15]:\n",
    "    path = os.path.join(output, file)\n",
    "    #print(path)\n",
    "    model = NaiveBayesModel.load(path)\n",
    "    val = model.transform(validate)\n",
    "    #get test accuracy\n",
    "    total = val.count()\n",
    "    correct = val.where(val['topic'] == val['NB_pred']).count()\n",
    "    print(path + ':', correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model/model_60_5: 0.34590163934426227\n",
      "model/model_60_6: 0.34098360655737703\n",
      "model/model_60_7: 0.3262295081967213\n"
     ]
    }
   ],
   "source": [
    "for file in model_list[15:18]:\n",
    "    path = os.path.join(output, file)\n",
    "    #print(path)\n",
    "    model = NaiveBayesModel.load(path)\n",
    "    val = model.transform(validate)\n",
    "    #get test accuracy\n",
    "    total = val.count()\n",
    "    correct = val.where(val['topic'] == val['NB_pred']).count()\n",
    "    print(path + ':', correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model/model_60_8: 0.34590163934426227\n",
      "model/model_60_9: 0.32459016393442625\n",
      "model/model_70_0: 0.32295081967213113\n"
     ]
    }
   ],
   "source": [
    "for file in model_list[18:21]:\n",
    "    path = os.path.join(output, file)\n",
    "    #print(path)\n",
    "    model = NaiveBayesModel.load(path)\n",
    "    val = model.transform(validate)\n",
    "    #get test accuracy\n",
    "    total = val.count()\n",
    "    correct = val.where(val['topic'] == val['NB_pred']).count()\n",
    "    print(path + ':', correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model/model_70_1: 0.32459016393442625\n",
      "model/model_70_2: 0.319672131147541\n",
      "model/model_70_3: 0.33934426229508197\n"
     ]
    }
   ],
   "source": [
    "for file in model_list[21:24]:\n",
    "    path = os.path.join(output, file)\n",
    "    #print(path)\n",
    "    model = NaiveBayesModel.load(path)\n",
    "    val = model.transform(validate)\n",
    "    #get test accuracy\n",
    "    total = val.count()\n",
    "    correct = val.where(val['topic'] == val['NB_pred']).count()\n",
    "    print(path + ':', correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model/model_70_4: 0.3360655737704918\n",
      "model/model_70_5: 0.33278688524590166\n",
      "model/model_70_6: 0.33114754098360655\n"
     ]
    }
   ],
   "source": [
    "model_list = os.listdir(output)\n",
    "for file in model_list[24:27]:\n",
    "    path = os.path.join(output, file)\n",
    "    #print(path)\n",
    "    model = NaiveBayesModel.load(path)\n",
    "    val = model.transform(validate)\n",
    "    #get test accuracy\n",
    "    total = val.count()\n",
    "    correct = val.where(val['topic'] == val['NB_pred']).count()\n",
    "    print(path + ':', correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model/model_70_7: 0.34098360655737703\n",
      "model/model_70_8: 0.3262295081967213\n",
      "model/model_70_9: 0.33934426229508197\n"
     ]
    }
   ],
   "source": [
    "for file in model_list[27:30]:\n",
    "    path = os.path.join(output, file)\n",
    "    model = NaiveBayesModel.load(path)\n",
    "    val = model.transform(validate)\n",
    "    #get test accuracy\n",
    "    total = val.count()\n",
    "    correct = val.where(val['topic'] == val['NB_pred']).count()\n",
    "    print(path + ':', correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
